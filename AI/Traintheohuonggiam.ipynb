{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1905968,"sourceType":"datasetVersion","datasetId":1136210}],"dockerImageVersionId":31240,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# =========================================================\n# FULL CELL: PTB-XL (Kaggle) ‚Äì Load ECG + c√¢n b·∫±ng d·ªØ li·ªáu t·ªëi ∆∞u\n# =========================================================\n\n!pip install -q wfdb\n\nimport wfdb\nimport pandas as pd\nimport numpy as np\nimport ast\nimport os\nimport gc\nimport h5py\n\nfrom collections import Counter\nfrom sklearn.model_selection import train_test_split\n\n# =========================\n# DATA PATH (KAGGLE)\n# =========================\nDATA_PATH = \"/kaggle/input/ptb-xl-dataset/ptb-xl-a-large-publicly-available-electrocardiography-dataset-1.0.1\"\n\n# =========================\n# LOAD METADATA\n# =========================\ndf = pd.read_csv(f\"{DATA_PATH}/ptbxl_database.csv\")\nscp = pd.read_csv(f\"{DATA_PATH}/scp_statements.csv\", index_col=0)\n\n# =========================\n# SUPERCLASS MAPPING (CHU·∫®N PAPER PTB-XL)\n# =========================\ndef get_superclass(scp_codes_str):\n    if pd.isna(scp_codes_str):\n        return None\n    try:\n        scp_codes = ast.literal_eval(scp_codes_str)\n    except:\n        return None\n\n    diagnostic_classes = []\n    for code in scp_codes.keys():\n        if code in scp.index and scp.loc[code, \"diagnostic\"] == 1:\n            diagnostic_classes.append(scp.loc[code, \"diagnostic_class\"])\n\n    # ∆Øu ti√™n ch·∫©n ƒëo√°n b·ªánh > normal\n    for cls in [\"MI\", \"STTC\", \"CD\", \"HYP\", \"NORM\"]:\n        if cls in diagnostic_classes:\n            return cls\n    return None\n\ndf[\"superclass\"] = df[\"scp_codes\"].apply(get_superclass)\n\nCLASSES = [\"NORM\", \"MI\", \"STTC\", \"CD\", \"HYP\"]\ndf = df[df[\"superclass\"].isin(CLASSES)].copy()\n\nprint(\"Ph√¢n b·ªë l·ªõp g·ªëc:\")\nprint(Counter(df[\"superclass\"]))\n\n# =========================\n# LOAD ECG SIGNAL (FIX PATH)\n# =========================\ndef load_ecg(filename_hr, filename_lr):\n    path_hr = f\"{DATA_PATH}/{filename_hr}\"\n    path_lr = f\"{DATA_PATH}/{filename_lr}\"\n\n    if os.path.exists(path_hr + \".dat\"):\n        signal, _ = wfdb.rdsamp(path_hr)\n    elif os.path.exists(path_lr + \".dat\"):\n        signal, _ = wfdb.rdsamp(path_lr)\n        signal = np.repeat(signal, 5, axis=0)  # 100Hz ‚Üí 500Hz\n    else:\n        return None\n\n    # Chu·∫©n ho√° ƒë·ªô d√†i = 10s (5000)\n    if signal.shape[0] > 5000:\n        signal = signal[:5000]\n    elif signal.shape[0] < 5000:\n        signal = np.pad(signal, ((0, 5000 - signal.shape[0]), (0, 0)))\n\n    return signal.astype(np.float32)\n\n# =========================\n# LOAD ALL ECG\n# =========================\nprint(\"\\nLoading ECG signals (~15 ph√∫t)...\")\n\nX, y = [], []\n\nfor _, row in df.iterrows():\n    sig = load_ecg(row[\"filename_hr\"], row[\"filename_lr\"])\n    if sig is not None:\n        X.append(sig)\n        y.append(row[\"superclass\"])\n\nX = np.array(X)\ny = np.array(y)\n\nprint(\"\\nLoaded ECG:\", X.shape)\nprint(\"Ph√¢n b·ªë l·ªõp sau load:\", Counter(y))\n\n# =========================\n# C√ÇN B·∫∞NG D·ªÆ LI·ªÜU (BEST PRACTICE)\n# =========================\n\"\"\"\nChi·∫øn l∆∞·ª£c:\n- Gi·ªØ to√†n b·ªô HYP (hi·∫øm nh·∫•t)\n- C√°c l·ªõp l·ªõn ‚Üí cap ·ªü m·ª©c h·ª£p l√Ω\n- Kh√¥ng l√†m dataset qu√° nh·ªè\n\"\"\"\n\nnp.random.seed(42)\n\nCAP = 2500   # b·∫°n c√≥ th·ªÉ tƒÉng 3000‚Äì4000 n·∫øu GPU ƒë·ªß\n\nX_bal, y_bal = [], []\n\nfor cls in CLASSES:\n    idx = np.where(y == cls)[0]\n\n    if len(idx) > CAP:\n        idx = np.random.choice(idx, CAP, replace=False)\n\n    X_bal.append(X[idx])\n    y_bal.append(y[idx])\n\nX_bal = np.concatenate(X_bal)\ny_bal = np.concatenate(y_bal)\n\nprint(\"\\nSau c√¢n b·∫±ng (cap-based):\")\nprint(Counter(y_bal))\nprint(\"Total samples:\", len(y_bal))\n\n# =========================\n# SHUFFLE + SPLIT\n# =========================\nperm = np.random.permutation(len(y_bal))\nX_bal = X_bal[perm]\ny_bal = y_bal[perm]\n\nX_train, X_val, y_train, y_val = train_test_split(\n    X_bal,\n    y_bal,\n    test_size=0.2,\n    stratify=y_bal,\n    random_state=42\n)\n\nprint(\"\\nTrain:\", X_train.shape)\nprint(\"Val  :\", X_val.shape)\n\n# =========================\n# SAVE HDF5\n# =========================\nwith h5py.File(\"ptbxl_train_balanced.h5\", \"w\") as f:\n    f.create_dataset(\"ecgs\", data=X_train, compression=\"gzip\")\n    f.create_dataset(\"labels\", data=y_train.astype(\"S\"))\n\nwith h5py.File(\"ptbxl_val_balanced.h5\", \"w\") as f:\n    f.create_dataset(\"ecgs\", data=X_val, compression=\"gzip\")\n    f.create_dataset(\"labels\", data=y_val.astype(\"S\"))\n\nprint(\"\\n‚úÖ FILE ƒê√É L∆ØU:\")\nprint(\" - ptbxl_train_balanced.h5\")\nprint(\" - ptbxl_val_balanced.h5\")\n\n# =========================\n# CLEAN RAM\n# =========================\ndel X, y, X_bal, y_bal, X_train, X_val, y_train, y_val\ngc.collect()\n\nprint(\"\\nüöÄ D·ªÆ LI·ªÜU ƒê√É S·∫¥N S√ÄNG TRAIN (CNN / Transformer ECG)\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-27T05:21:14.414571Z","iopub.execute_input":"2025-12-27T05:21:14.415456Z","iopub.status.idle":"2025-12-27T05:31:48.572973Z","shell.execute_reply.started":"2025-12-27T05:21:14.415423Z","shell.execute_reply":"2025-12-27T05:31:48.572108Z"}},"outputs":[{"name":"stdout","text":"Ph√¢n b·ªë l·ªõp g·ªëc:\nCounter({'NORM': 9083, 'MI': 5486, 'STTC': 3905, 'CD': 2418, 'HYP': 538})\n\nLoading ECG signals (~15 ph√∫t)...\n\nLoaded ECG: (21430, 5000, 12)\nPh√¢n b·ªë l·ªõp sau load: Counter({'NORM': 9083, 'MI': 5486, 'STTC': 3905, 'CD': 2418, 'HYP': 538})\n\nSau c√¢n b·∫±ng (cap-based):\nCounter({'NORM': 2500, 'MI': 2500, 'STTC': 2500, 'CD': 2418, 'HYP': 538})\nTotal samples: 10456\n\nTrain: (8364, 5000, 12)\nVal  : (2092, 5000, 12)\n\n‚úÖ FILE ƒê√É L∆ØU:\n - ptbxl_train_balanced.h5\n - ptbxl_val_balanced.h5\n\nüöÄ D·ªÆ LI·ªÜU ƒê√É S·∫¥N S√ÄNG TRAIN (CNN / Transformer ECG)\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"# =========================================================\n# CELL 2: Advanced preprocessing + imbalance-aware training\n# =========================================================\n\nimport h5py\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import TensorDataset, DataLoader\nfrom scipy.signal import butter, filtfilt\nfrom collections import Counter\n\n# =========================\n# LOAD DATA FROM HDF5\n# =========================\nwith h5py.File(\"ptbxl_train_balanced.h5\", \"r\") as f:\n    X_train = f[\"ecgs\"][:]              # (N, 5000, 12)\n    y_train = f[\"labels\"][:].astype(str)\n\nwith h5py.File(\"ptbxl_val_balanced.h5\", \"r\") as f:\n    X_val = f[\"ecgs\"][:]\n    y_val = f[\"labels\"][:].astype(str)\n\nprint(\"Train shape:\", X_train.shape)\nprint(\"Train class distribution:\", Counter(y_train))\n\n# =========================\n# 1Ô∏è‚É£ BANDPASS FILTER (0.5‚Äì40 Hz)\n# =========================\ndef bandpass_filter(ecg, low=0.5, high=40.0, fs=500, order=5):\n    nyq = 0.5 * fs\n    low /= nyq\n    high /= nyq\n    b, a = butter(order, [low, high], btype=\"band\")\n    return filtfilt(b, a, ecg, axis=0)\n\nprint(\"\\nApplying bandpass filter...\")\nX_train = np.array([bandpass_filter(x) for x in X_train])\nX_val   = np.array([bandpass_filter(x) for x in X_val])\n\n# =========================\n# 2Ô∏è‚É£ Z-SCORE NORMALIZATION (PER LEAD)\n# =========================\ndef zscore_per_lead(ecg):\n    mean = ecg.mean(axis=0, keepdims=True)\n    std = ecg.std(axis=0, keepdims=True) + 1e-8\n    return (ecg - mean) / std\n\nprint(\"Applying z-score normalization...\")\nX_train = np.array([zscore_per_lead(x) for x in X_train])\nX_val   = np.array([zscore_per_lead(x) for x in X_val])\n\nprint(\"Preprocessing DONE\")\n\n# =========================\n# LABEL ENCODING\n# =========================\nCLASSES = [\"NORM\", \"MI\", \"STTC\", \"CD\", \"HYP\"]\nlabel_to_idx = {c: i for i, c in enumerate(CLASSES)}\n\ny_train_idx = np.array([label_to_idx[y] for y in y_train])\ny_val_idx   = np.array([label_to_idx[y] for y in y_val])\n\n# =========================\n# 3Ô∏è‚É£ CLASS-WEIGHTED LOSS\n# =========================\ncounter = Counter(y_train)\ntotal = sum(counter.values())\n\nclass_weights = torch.tensor(\n    [total / (len(CLASSES) * counter[c]) for c in CLASSES],\n    dtype=torch.float32\n)\n\nprint(\"\\nClass weights:\", class_weights)\n\ncriterion = nn.CrossEntropyLoss(weight=class_weights.cuda())\n\n# =========================\n# PYTORCH DATALOADER\n# =========================\ntrain_ds = TensorDataset(\n    torch.tensor(X_train).float(),\n    torch.tensor(y_train_idx).long()\n)\n\nval_ds = TensorDataset(\n    torch.tensor(X_val).float(),\n    torch.tensor(y_val_idx).long()\n)\n\ntrain_loader = DataLoader(train_ds, batch_size=16, shuffle=True)\nval_loader   = DataLoader(val_ds, batch_size=16, shuffle=False)\n\n# =========================\n# 4Ô∏è‚É£ MIXUP ECG (TRAIN ONLY)\n# =========================\ndef mixup_ecg(x, y, alpha=0.2):\n    lam = np.random.beta(alpha, alpha)\n    idx = torch.randperm(x.size(0)).cuda()\n    mixed_x = lam * x + (1 - lam) * x[idx]\n    return mixed_x, y, y[idx], lam\n\ndef mixup_criterion(criterion, pred, y_a, y_b, lam):\n    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n\nprint(\"\\nüöÄ DataLoader + preprocessing + class-weight + mixup READY\")\nprint(\"‚û°Ô∏è Cell n√†y k·∫øt th√∫c, b·∫°n c√≥ th·ªÉ TRAIN MODEL NGAY\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T05:35:43.916561Z","iopub.execute_input":"2025-12-27T05:35:43.917455Z","iopub.status.idle":"2025-12-27T05:36:38.124824Z","shell.execute_reply.started":"2025-12-27T05:35:43.917427Z","shell.execute_reply":"2025-12-27T05:36:38.123975Z"}},"outputs":[{"name":"stdout","text":"Train shape: (8364, 5000, 12)\nTrain class distribution: Counter({'MI': 2000, 'NORM': 2000, 'STTC': 2000, 'CD': 1934, 'HYP': 430})\n\nApplying bandpass filter...\nApplying z-score normalization...\nPreprocessing DONE\n\nClass weights: tensor([0.8364, 0.8364, 0.8364, 0.8649, 3.8902])\n\nüöÄ DataLoader + preprocessing + class-weight + mixup READY\n‚û°Ô∏è Cell n√†y k·∫øt th√∫c, b·∫°n c√≥ th·ªÉ TRAIN MODEL NGAY\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"# =========================================================\n# CELL: Patient-wise Train / Val / Test split (PTB-XL)\n# =========================================================\n\nfrom sklearn.model_selection import GroupShuffleSplit\nfrom collections import Counter\nimport numpy as np\n\n# df ƒë√£ c√≥ c·ªôt 'patient_id' v√† 'superclass'\npatients = df[\"patient_id\"].values\nlabels = df[\"superclass\"].values\n\ngss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\ntrain_val_idx, test_idx = next(gss.split(df, labels, groups=patients))\n\ndf_trainval = df.iloc[train_val_idx]\ndf_test = df.iloc[test_idx]\n\nprint(\"Test distribution:\")\nprint(Counter(df_test[\"superclass\"]))\n\n# ---- split train / val ----\ngss2 = GroupShuffleSplit(n_splits=1, test_size=0.125, random_state=42)\ntrain_idx, val_idx = next(\n    gss2.split(\n        df_trainval,\n        df_trainval[\"superclass\"],\n        groups=df_trainval[\"patient_id\"]\n    )\n)\n\ndf_train = df_trainval.iloc[train_idx]\ndf_val = df_trainval.iloc[val_idx]\n\nprint(\"\\nTrain distribution:\")\nprint(Counter(df_train[\"superclass\"]))\n\nprint(\"\\nVal distribution:\")\nprint(Counter(df_val[\"superclass\"]))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T05:43:01.148114Z","iopub.execute_input":"2025-12-27T05:43:01.148814Z","iopub.status.idle":"2025-12-27T05:43:01.177751Z","shell.execute_reply.started":"2025-12-27T05:43:01.148781Z","shell.execute_reply":"2025-12-27T05:43:01.177008Z"}},"outputs":[{"name":"stdout","text":"Test distribution:\nCounter({'NORM': 1808, 'MI': 1117, 'STTC': 793, 'CD': 475, 'HYP': 103})\n\nTrain distribution:\nCounter({'NORM': 6341, 'MI': 3855, 'STTC': 2713, 'CD': 1704, 'HYP': 386})\n\nVal distribution:\nCounter({'NORM': 934, 'MI': 514, 'STTC': 399, 'CD': 239, 'HYP': 49})\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"# =========================================================\n# CELL: SAFE TEST EXPORT (aligned with TRAIN pipeline)\n# =========================================================\n\nimport wfdb\nimport numpy as np\nimport os\nimport h5py\nimport gc\nfrom collections import Counter\nfrom scipy.signal import butter, filtfilt\n\n# =========================\n# CONFIG (GI·ªêNG TRAIN)\n# =========================\nDATA_PATH = \"/kaggle/input/ptb-xl-dataset/ptb-xl-a-large-publicly-available-electrocardiography-dataset-1.0.1\"\nFS = 500\nTARGET_LEN = 5000\nCLASSES = [\"NORM\", \"MI\", \"STTC\", \"CD\", \"HYP\"]\n\n# =========================\n# ECG LOADER (GI·ªêNG TRAIN)\n# =========================\ndef load_ecg(filename_hr, filename_lr):\n    path_hr = f\"{DATA_PATH}/{filename_hr}\"\n    path_lr = f\"{DATA_PATH}/{filename_lr}\"\n\n    if os.path.exists(path_hr + \".dat\"):\n        sig, _ = wfdb.rdsamp(path_hr)\n    elif os.path.exists(path_lr + \".dat\"):\n        sig, _ = wfdb.rdsamp(path_lr)\n        sig = np.repeat(sig, 5, axis=0)  # 100Hz ‚Üí 500Hz\n    else:\n        return None\n\n    # Fix length = 5000\n    if sig.shape[0] > TARGET_LEN:\n        sig = sig[:TARGET_LEN]\n    elif sig.shape[0] < TARGET_LEN:\n        sig = np.pad(sig, ((0, TARGET_LEN - sig.shape[0]), (0, 0)))\n\n    return sig.astype(np.float32)  # √âP FLOAT32 NGAY T·ª™ ƒê·∫¶U\n\n# =========================\n# BANDPASS FILTER (0.5‚Äì40Hz)\n# =========================\ndef bandpass_filter(ecg, low=0.5, high=40.0, fs=500, order=5):\n    nyq = 0.5 * fs\n    b, a = butter(order, [low / nyq, high / nyq], btype=\"band\")\n    ecg = filtfilt(b, a, ecg, axis=0)\n    return ecg.astype(np.float32)  # √âP L·∫†I FLOAT32\n\n# =========================\n# Z-SCORE PER LEAD\n# =========================\ndef zscore_per_lead(ecg):\n    mean = ecg.mean(axis=0, keepdims=True)\n    std = ecg.std(axis=0, keepdims=True) + 1e-8\n    ecg = (ecg - mean) / std\n    return ecg.astype(np.float32)  # √âP FLOAT32\n\n# =========================\n# LOAD + PREPROCESS TEST ECG\n# =========================\nprint(\"Loading & preprocessing TEST ECG (SAFE MODE)...\")\n\nX_test, y_test = [], []\n\nfor _, row in df_test.iterrows():\n    sig = load_ecg(row[\"filename_hr\"], row[\"filename_lr\"])\n    if sig is None:\n        continue\n\n    sig = bandpass_filter(sig)\n    sig = zscore_per_lead(sig)\n\n    X_test.append(sig)\n    y_test.append(row[\"superclass\"])\n\nX_test = np.stack(X_test).astype(np.float32)\ny_test = np.array(y_test)\n\nprint(\"\\nTEST SHAPE:\", X_test.shape)\nprint(\"TEST CLASS DISTRIBUTION:\", Counter(y_test))\nprint(\"TEST DTYPE:\", X_test.dtype)\n\n# =========================\n# SAVE HDF5 (GI·ªêNG TRAIN)\n# =========================\nwith h5py.File(\"ptbxl_test.h5\", \"w\") as f:\n    f.create_dataset(\"ecgs\", data=X_test, compression=\"gzip\")\n    f.create_dataset(\"labels\", data=y_test.astype(\"S\"))\n\nprint(\"\\n‚úÖ SAVED: ptbxl_test.h5 (SAFE & ALIGNED)\")\n\n# =========================\n# CLEAN RAM\n# =========================\ndel X_test, y_test\ngc.collect()\n\nprint(\"\\nüöÄ TEST SET READY ‚Äî GUARANTEED NO LEAK / NO DTYPE BUG\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T05:51:21.973179Z","iopub.execute_input":"2025-12-27T05:51:21.973502Z","iopub.status.idle":"2025-12-27T05:52:58.479065Z","shell.execute_reply.started":"2025-12-27T05:51:21.973479Z","shell.execute_reply":"2025-12-27T05:52:58.478367Z"}},"outputs":[{"name":"stdout","text":"Loading & preprocessing TEST ECG (SAFE MODE)...\n\nTEST SHAPE: (4296, 5000, 12)\nTEST CLASS DISTRIBUTION: Counter({'NORM': 1808, 'MI': 1117, 'STTC': 793, 'CD': 475, 'HYP': 103})\nTEST DTYPE: float32\n\n‚úÖ SAVED: ptbxl_test.h5 (SAFE & ALIGNED)\n\nüöÄ TEST SET READY ‚Äî GUARANTEED NO LEAK / NO DTYPE BUG\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"import h5py\n\nwith h5py.File(\"ptbxl_test.h5\", \"r\") as f:\n    print(f[\"ecgs\"].dtype)\n    print(f[\"ecgs\"].shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T05:54:01.229971Z","iopub.execute_input":"2025-12-27T05:54:01.230544Z","iopub.status.idle":"2025-12-27T05:54:01.236400Z","shell.execute_reply.started":"2025-12-27T05:54:01.230520Z","shell.execute_reply":"2025-12-27T05:54:01.235717Z"}},"outputs":[{"name":"stdout","text":"float32\n(4296, 5000, 12)\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"# =========================================================\n# CELL 1: Setup & DataLoader\n# =========================================================\nimport h5py\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.preprocessing import LabelEncoder\n\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nBATCH_SIZE = 32\nEPOCHS = 50\nPATIENCE = 7\n\nCLASSES = [\"NORM\", \"MI\", \"STTC\", \"CD\", \"HYP\"]\nNUM_CLASSES = len(CLASSES)\n\nlabel_encoder = LabelEncoder()\nlabel_encoder.fit(CLASSES)\n\nclass ECGDataset(Dataset):\n    def __init__(self, h5_path):\n        with h5py.File(h5_path, \"r\") as f:\n            self.X = f[\"ecgs\"][:]\n            self.y = f[\"labels\"][:].astype(str)\n        self.y = label_encoder.transform(self.y)\n\n    def __len__(self):\n        return len(self.y)\n\n    def __getitem__(self, idx):\n        x = torch.tensor(self.X[idx]).float().permute(1, 0)  # (C, T)\n        y = torch.tensor(self.y[idx]).long()\n        return x, y\n\ntrain_loader = DataLoader(ECGDataset(\"ptbxl_train_balanced.h5\"),\n                          batch_size=BATCH_SIZE, shuffle=True)\nval_loader   = DataLoader(ECGDataset(\"ptbxl_val_balanced.h5\"),\n                          batch_size=BATCH_SIZE, shuffle=False)\ntest_loader  = DataLoader(ECGDataset(\"ptbxl_test.h5\"),\n                          batch_size=BATCH_SIZE, shuffle=False)\n\nprint(\"DataLoader READY | Device:\", DEVICE)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T05:48:37.579958Z","iopub.execute_input":"2025-12-27T05:48:37.580592Z","iopub.status.idle":"2025-12-27T05:49:08.214413Z","shell.execute_reply.started":"2025-12-27T05:48:37.580565Z","shell.execute_reply":"2025-12-27T05:49:08.213290Z"}},"outputs":[{"name":"stdout","text":"DataLoader READY | Device: cuda\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport numpy as np\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.metrics import accuracy_score\nimport h5py\n\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", DEVICE)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T06:00:09.373785Z","iopub.execute_input":"2025-12-27T06:00:09.374320Z","iopub.status.idle":"2025-12-27T06:00:09.379657Z","shell.execute_reply.started":"2025-12-27T06:00:09.374296Z","shell.execute_reply":"2025-12-27T06:00:09.378644Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"from torch.utils.data import Dataset\nimport torch\nimport h5py\n\nCLASSES = [\"NORM\", \"MI\", \"STTC\", \"CD\", \"HYP\"]\nlabel_to_idx = {c: i for i, c in enumerate(CLASSES)}\n\nclass ECGDataset(Dataset):\n    def __init__(self, h5_path):\n        with h5py.File(h5_path, \"r\") as f:\n            self.X = f[\"ecgs\"][:]\n            self.y = f[\"labels\"][:]\n\n        self.X = torch.tensor(self.X, dtype=torch.float32)\n\n        # ---- FIX LABEL STRING -> INT ----\n        self.y = torch.tensor(\n            [label_to_idx[lbl.decode()] for lbl in self.y],\n            dtype=torch.long\n        )\n\n    def __len__(self):\n        return len(self.y)\n\n    def __getitem__(self, idx):\n        return self.X[idx], self.y[idx]\ntrain_ds = ECGDataset(\"ptbxl_train_balanced.h5\")\nval_ds   = ECGDataset(\"ptbxl_val_balanced.h5\")\n\ntrain_loader = DataLoader(train_ds, batch_size=32, shuffle=True, num_workers=2)\nval_loader   = DataLoader(val_ds, batch_size=32, shuffle=False)\n\nprint(\"Train samples:\", len(train_ds))\nprint(\"Val samples:\", len(val_ds))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T06:02:14.424366Z","iopub.execute_input":"2025-12-27T06:02:14.424653Z","iopub.status.idle":"2025-12-27T06:02:31.460035Z","shell.execute_reply.started":"2025-12-27T06:02:14.424633Z","shell.execute_reply":"2025-12-27T06:02:31.459091Z"}},"outputs":[{"name":"stdout","text":"Train samples: 8364\nVal samples: 2092\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"from collections import Counter\n\ndef mixup_ecg(x, y, alpha=0.2):\n    if alpha <= 0:\n        return x, y, y, 1.0\n\n    lam = np.random.beta(alpha, alpha)\n    idx = torch.randperm(x.size(0)).to(x.device)\n\n    return lam*x + (1-lam)*x[idx], y, y[idx], lam\n\n\ndef mixup_criterion(criterion, pred, y_a, y_b, lam):\n    return lam*criterion(pred, y_a) + (1-lam)*criterion(pred, y_b)\n\n\n# ---- class weights ----\nlabels = [y.item() for _, y in train_ds]\ncounter = Counter(labels)\ntotal = sum(counter.values())\n\nweights = torch.tensor(\n    [total/(len(counter)*counter[i]) for i in range(len(counter))],\n    dtype=torch.float32\n).to(DEVICE)\n\ncriterion = nn.CrossEntropyLoss(weight=weights)\nprint(\"Class weights:\", weights)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T06:03:04.572813Z","iopub.execute_input":"2025-12-27T06:03:04.573067Z","iopub.status.idle":"2025-12-27T06:03:05.051425Z","shell.execute_reply.started":"2025-12-27T06:03:04.573051Z","shell.execute_reply":"2025-12-27T06:03:05.050652Z"}},"outputs":[{"name":"stdout","text":"Class weights: tensor([0.8364, 0.8364, 0.8364, 0.8649, 3.8902], device='cuda:0')\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"class Xception1D(nn.Module):\n    def __init__(self, num_classes=5):\n        super().__init__()\n        self.conv = nn.Sequential(\n            nn.Conv1d(12, 32, 3, padding=1),\n            nn.ReLU(),\n            nn.Conv1d(32, 64, 3, padding=1, groups=32),\n            nn.ReLU(),\n            nn.AdaptiveAvgPool1d(1)\n        )\n        self.fc = nn.Linear(64, num_classes)\n\n    def forward(self, x):\n        x = x.permute(0,2,1)\n        x = self.conv(x).squeeze(-1)\n        return self.fc(x)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T06:03:19.871202Z","iopub.execute_input":"2025-12-27T06:03:19.871516Z","iopub.status.idle":"2025-12-27T06:03:19.876981Z","shell.execute_reply.started":"2025-12-27T06:03:19.871493Z","shell.execute_reply":"2025-12-27T06:03:19.876301Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"models = {\n    \"Xception1D\": Xception1D().to(DEVICE),\n    \"ResNet1D\":   ResNet1D().to(DEVICE),\n    \"CRNN1D\":     CRNN1D().to(DEVICE),\n}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T06:03:32.075858Z","iopub.execute_input":"2025-12-27T06:03:32.076172Z","iopub.status.idle":"2025-12-27T06:03:32.150995Z","shell.execute_reply.started":"2025-12-27T06:03:32.076118Z","shell.execute_reply":"2025-12-27T06:03:32.150416Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"def train_model(model, name, epochs=50, patience=7):\n    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n    history = {\n        \"train_loss\": [], \"val_loss\": [],\n        \"train_acc\": [],  \"val_acc\": []\n    }\n\n    best_val = 1e9\n    counter = 0\n\n    for epoch in range(1, epochs+1):\n\n        # ---- TRAIN ----\n        model.train()\n        tloss, yt, yp = [], [], []\n\n        for x,y in train_loader:\n            x,y = x.to(DEVICE), y.to(DEVICE)\n            optimizer.zero_grad()\n\n            x, y_a, y_b, lam = mixup_ecg(x,y)\n            out = model(x)\n            loss = mixup_criterion(criterion, out, y_a, y_b, lam)\n\n            loss.backward()\n            optimizer.step()\n\n            tloss.append(loss.item())\n            yt.extend(y.cpu().numpy())\n            yp.extend(out.argmax(1).cpu().numpy())\n\n        train_loss = np.mean(tloss)\n        train_acc = accuracy_score(yt, yp)\n\n        # ---- VAL ----\n        model.eval()\n        vloss, yt, yp = [], [], []\n\n        with torch.no_grad():\n            for x,y in val_loader:\n                x,y = x.to(DEVICE), y.to(DEVICE)\n                out = model(x)\n                loss = criterion(out,y)\n\n                vloss.append(loss.item())\n                yt.extend(y.cpu().numpy())\n                yp.extend(out.argmax(1).cpu().numpy())\n\n        val_loss = np.mean(vloss)\n        val_acc = accuracy_score(yt, yp)\n\n        print(\n            f\"{name} | Epoch {epoch:02d} | \"\n            f\"Train loss {train_loss:.4f} | Train acc {train_acc:.4f} | \"\n            f\"Val loss {val_loss:.4f} | Val acc {val_acc:.4f}\"\n        )\n\n        history[\"train_loss\"].append(train_loss)\n        history[\"val_loss\"].append(val_loss)\n        history[\"train_acc\"].append(train_acc)\n        history[\"val_acc\"].append(val_acc)\n\n        # ---- EARLY STOP ----\n        if val_loss < best_val:\n            best_val = val_loss\n            counter = 0\n            torch.save(model.state_dict(), f\"{name}.pt\")\n        else:\n            counter += 1\n            if counter >= patience:\n                print(f\"‚èπ Early stopping {name}\")\n                break\n\n    return history\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T06:03:39.260390Z","iopub.execute_input":"2025-12-27T06:03:39.260679Z","iopub.status.idle":"2025-12-27T06:03:39.270859Z","shell.execute_reply.started":"2025-12-27T06:03:39.260661Z","shell.execute_reply":"2025-12-27T06:03:39.270161Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"histories = {}\n\nfor name, model in models.items():\n    print(\"\\n\" + \"=\"*60)\n    histories[name] = train_model(model, name)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T06:03:50.922319Z","iopub.execute_input":"2025-12-27T06:03:50.923059Z","iopub.status.idle":"2025-12-27T06:06:45.278107Z","shell.execute_reply.started":"2025-12-27T06:03:50.923030Z","shell.execute_reply":"2025-12-27T06:06:45.276794Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nXception1D | Epoch 01 | Train loss 1.5977 | Train acc 0.2502 | Val loss 1.5655 | Val acc 0.1420\nXception1D | Epoch 02 | Train loss 1.5460 | Train acc 0.2704 | Val loss 1.5055 | Val acc 0.3533\nXception1D | Epoch 03 | Train loss 1.5071 | Train acc 0.3038 | Val loss 1.4661 | Val acc 0.3599\nXception1D | Epoch 04 | Train loss 1.4833 | Train acc 0.3016 | Val loss 1.4385 | Val acc 0.3939\nXception1D | Epoch 05 | Train loss 1.4516 | Train acc 0.3089 | Val loss 1.4216 | Val acc 0.4283\nXception1D | Epoch 06 | Train loss 1.4428 | Train acc 0.3092 | Val loss 1.4005 | Val acc 0.4235\nXception1D | Epoch 07 | Train loss 1.4313 | Train acc 0.3181 | Val loss 1.3917 | Val acc 0.4030\nXception1D | Epoch 08 | Train loss 1.4184 | Train acc 0.3075 | Val loss 1.3793 | Val acc 0.4316\nXception1D | Epoch 09 | Train loss 1.4192 | Train acc 0.3281 | Val loss 1.3676 | Val acc 0.4197\nXception1D | Epoch 10 | Train loss 1.4015 | Train acc 0.3305 | Val loss 1.3527 | Val acc 0.4340\nXception1D | Epoch 11 | Train loss 1.3895 | Train acc 0.3282 | Val loss 1.3464 | Val acc 0.4436\nXception1D | Epoch 12 | Train loss 1.3814 | Train acc 0.3274 | Val loss 1.3366 | Val acc 0.4388\nXception1D | Epoch 13 | Train loss 1.3743 | Train acc 0.3314 | Val loss 1.3249 | Val acc 0.4575\nXception1D | Epoch 14 | Train loss 1.3585 | Train acc 0.3553 | Val loss 1.3191 | Val acc 0.4493\nXception1D | Epoch 15 | Train loss 1.3508 | Train acc 0.3400 | Val loss 1.3021 | Val acc 0.4651\nXception1D | Epoch 16 | Train loss 1.3557 | Train acc 0.3379 | Val loss 1.2972 | Val acc 0.4637\nXception1D | Epoch 17 | Train loss 1.3281 | Train acc 0.3562 | Val loss 1.2904 | Val acc 0.4842\nXception1D | Epoch 18 | Train loss 1.3312 | Train acc 0.3592 | Val loss 1.2832 | Val acc 0.4756\nXception1D | Epoch 19 | Train loss 1.3306 | Train acc 0.3410 | Val loss 1.2751 | Val acc 0.4976\nXception1D | Epoch 20 | Train loss 1.3063 | Train acc 0.3472 | Val loss 1.2749 | Val acc 0.4766\nXception1D | Epoch 21 | Train loss 1.3150 | Train acc 0.3661 | Val loss 1.2682 | Val acc 0.5019\nXception1D | Epoch 22 | Train loss 1.3210 | Train acc 0.3611 | Val loss 1.2729 | Val acc 0.4665\nXception1D | Epoch 23 | Train loss 1.2995 | Train acc 0.3449 | Val loss 1.2565 | Val acc 0.4943\nXception1D | Epoch 24 | Train loss 1.2971 | Train acc 0.3525 | Val loss 1.2492 | Val acc 0.5072\nXception1D | Epoch 25 | Train loss 1.3042 | Train acc 0.3599 | Val loss 1.2470 | Val acc 0.5038\nXception1D | Epoch 26 | Train loss 1.3092 | Train acc 0.3685 | Val loss 1.2458 | Val acc 0.5024\nXception1D | Epoch 27 | Train loss 1.3016 | Train acc 0.3565 | Val loss 1.2381 | Val acc 0.5201\nXception1D | Epoch 28 | Train loss 1.2842 | Train acc 0.3600 | Val loss 1.2371 | Val acc 0.5014\nXception1D | Epoch 29 | Train loss 1.2783 | Train acc 0.3785 | Val loss 1.2314 | Val acc 0.5091\nXception1D | Epoch 30 | Train loss 1.2947 | Train acc 0.3633 | Val loss 1.2445 | Val acc 0.4943\nXception1D | Epoch 31 | Train loss 1.2893 | Train acc 0.3595 | Val loss 1.2444 | Val acc 0.4857\nXception1D | Epoch 32 | Train loss 1.2641 | Train acc 0.3923 | Val loss 1.2219 | Val acc 0.5206\nXception1D | Epoch 33 | Train loss 1.2826 | Train acc 0.3694 | Val loss 1.2279 | Val acc 0.5320\nXception1D | Epoch 34 | Train loss 1.2785 | Train acc 0.3685 | Val loss 1.2314 | Val acc 0.5387\nXception1D | Epoch 35 | Train loss 1.2544 | Train acc 0.3765 | Val loss 1.2170 | Val acc 0.5277\nXception1D | Epoch 36 | Train loss 1.2712 | Train acc 0.3766 | Val loss 1.2215 | Val acc 0.5096\nXception1D | Epoch 37 | Train loss 1.2750 | Train acc 0.3733 | Val loss 1.2206 | Val acc 0.5163\nXception1D | Epoch 38 | Train loss 1.2598 | Train acc 0.3615 | Val loss 1.2167 | Val acc 0.5349\nXception1D | Epoch 39 | Train loss 1.2768 | Train acc 0.3733 | Val loss 1.2186 | Val acc 0.5196\nXception1D | Epoch 40 | Train loss 1.2784 | Train acc 0.3711 | Val loss 1.2208 | Val acc 0.5043\nXception1D | Epoch 41 | Train loss 1.2645 | Train acc 0.3922 | Val loss 1.2202 | Val acc 0.5096\nXception1D | Epoch 42 | Train loss 1.2578 | Train acc 0.3867 | Val loss 1.2119 | Val acc 0.5339\nXception1D | Epoch 43 | Train loss 1.2582 | Train acc 0.3826 | Val loss 1.2160 | Val acc 0.5081\nXception1D | Epoch 44 | Train loss 1.2594 | Train acc 0.3621 | Val loss 1.2102 | Val acc 0.5282\nXception1D | Epoch 45 | Train loss 1.2618 | Train acc 0.3795 | Val loss 1.2203 | Val acc 0.5105\nXception1D | Epoch 46 | Train loss 1.2572 | Train acc 0.3709 | Val loss 1.2143 | Val acc 0.5172\nXception1D | Epoch 47 | Train loss 1.2595 | Train acc 0.3867 | Val loss 1.2118 | Val acc 0.5196\nXception1D | Epoch 48 | Train loss 1.2499 | Train acc 0.3688 | Val loss 1.2078 | Val acc 0.5272\nXception1D | Epoch 49 | Train loss 1.2506 | Train acc 0.3892 | Val loss 1.2080 | Val acc 0.5244\nXception1D | Epoch 50 | Train loss 1.2352 | Train acc 0.3996 | Val loss 1.2019 | Val acc 0.5315\n\n============================================================\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_47/703178198.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"=\"\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mhistories\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_47/4060667585.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, name, epochs, patience)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmixup_ecg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmixup_criterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_47/1662775972.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 375\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    368\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m             )\n\u001b[0;32m--> 370\u001b[0;31m         return F.conv1d(\n\u001b[0m\u001b[1;32m    371\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m         )\n","\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [64, 12, 7], expected input[32, 5000, 12] to have 12 channels, but got 5000 channels instead"],"ename":"RuntimeError","evalue":"Given groups=1, weight of size [64, 12, 7], expected input[32, 5000, 12] to have 12 channels, but got 5000 channels instead","output_type":"error"}],"execution_count":37},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}